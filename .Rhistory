lm
lm <- train(
SalePrice~.,
data = train_pp,
#preProcess = c("center","scale"),
metric = "RMSE",
method = "lm",
trControl = myControl
)
lm
lm <- train(
SalePrice~.,
data = train_pp,
preProcess = c("center","scale"),
metric = "RMSE",
method = "lm",
trControl = myControl
)
lm
lm <- train(
SalePrice~.,
data = train_pp,
preProcess = c("nzv","center","scale"),
metric = "RMSE",
method = "lm",
trControl = myControl
)
lm
lm_pca <- train(
SalePrice~.,
data = train_pp,
preProcess = c("zv","center","scale","pca"),
metric = "RMSE",
method = "lm",
trControl = myControl
)
lm_pca
lm_pca <- train(
SalePrice~.,
data = train_pp,
preProcess = c("zv","pca"),
metric = "RMSE",
method = "lm",
trControl = myControl
)
lm_pca
lm_pca <- train(
SalePrice~.,
data = train_pp,
preProcess = c("zv","center","scale","pca"),
metric = "RMSE",
method = "lm",
trControl = myControl
)
lm_pca
lm_pca <- train(
SalePrice~.,
data = train_pp,
preProcess = c("zv","pca"),
metric = "RMSE",
method = "lm",
trControl = myControl
)
lm_pca
glmnet <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "glmnet",
trControl = myControl
)
?seq
glmnet
glmnet <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "glmnet",
trControl = myControl
tuneGrid = expand.grid(
alpha = 0:1,
lambda = seq(1000,100000,100)
)
)
##GLMNET Models
glmnet <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "glmnet",
trControl = myControl,
tuneGrid = expand.grid(
alpha = 0:1,
lambda = seq(1000,100000,100)
)
)
glmnet
plot(glmnet)
min(glmnet$results$RMSE)
glmnet <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "glmnet",
trControl = myControl,
tuneGrid = expand.grid(
alpha = seq(0,1,.1),
lambda = seq(1000,50000,100)
)
)
min(glmnet$results$RMSE)
plot(glmnet)
rf_mod <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "ranger",
trControl = myControl
)
str(train_pp)
rf_mod <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "ranger",
trControl = myControl
)
rf_mod <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "rf",
trControl = myControl
)
rf_mod
plot(rf_mod)
rf_mod <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "ranger",
trControl = myControl
)
install.packages("ranger")
install.packages("ranger")
install.packages("ranger")
install.packages("e1071")
library(devtools)
devtools::install_github("imbs-hl/ranger")
library(here)
library(tidyverse)
library(caret)
rf_mod <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "ranger",
trControl = myControl
)
rf_mod <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "rf",
trControl = myControl
)
rf_mod
rf_mod <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "rf",
trControl = myControl
tuneGrid = expand.grid(
mtry = seq(100, 150, 5)
)
)
##RF Models
rf_mod <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "rf",
trControl = myControl,
tuneGrid = expand.grid(
mtry = seq(100, 150, 5)
)
)
rf_mod
glmnet <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "glmnet",
trControl = myControl,
tuneGrid = expand.grid(
alpha = seq(0,1,.1),
lambda = seq(1000,50000,100)
)
)
mod_list <- list(lm = lm,pca = lm_pca,glmnet = glmnet,rf = rf_mod)
resamp <- resamples(mod_list)
bwplot(resamp,metric = "RMSE")
dotplot(resamp, metric = "RMSE")
parallelplot(resamp, metric = "RMSE")
dotplot(resamp, metric = "RMSE")
xgb_lm <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "xgbLinear",
trControl = myControl
)
xgb_lm
mod_list <- list(lm = lm,pca = lm_pca,glmnet = glmnet,rf = rf_mod, XGBLinear = xgb_lm)
resamp <- resamples(mod_list)
bwplot(resamp,metric = "RMSE")
xgb_tree <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "xgbTree",
trControl = myControl
)
mod_list <- list(lm = lm,pca = lm_pca,glmnet = glmnet,rf = rf_mod, XGBLinear = xgb_lm, XGBTree = xgb_tree)
resamp <- resamples(mod_list)
dotplot(resamp, metric = "RMSE")
gbm <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "gbm",
trControl = myControl
)
gbm
mod_list <- list(lm = lm,pca = lm_pca,glmnet = glmnet,rf = rf_mod, XGBLinear = xgb_lm, XGBTree = xgb_tree, gbm = gbm)
resamp <- resamples(mod_list)
bwplot(resamp,metric = "RMSE")
glmboost <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "glmboost",
trControl = myControl
)
rpart <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "rpart",
trControl = myControl
)
mod_list <- list(lm = lm,pca = lm_pca,glmnet = glmnet,rf = rf_mod, XGBLinear = xgb_lm, XGBTree = xgb_tree, gbm = gbm, rpart = rpart)
resamp <- resamples(mod_list)
bwplot(resamp,metric = "RMSE")
svmLinear <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "svmLinear",
trControl = myControl
)
mod_list <- list(lm = lm,pca = lm_pca,glmnet = glmnet,rf = rf_mod, XGBLinear = xgb_lm, XGBTree = xgb_tree, gbm = gbm, rpart = rpart, svmLinear = svmLinear)
resamp <- resamples(mod_list)
bwplot(resamp,metric = "RMSE")
xgbTree <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "xgbTree",
trControl = myControl,
tuneGrid = expand.grid(
nrounds=c(350),
max_depth = c(4, 6),
eta = c(0.05, 0.1),
gamma = c(0.01),
colsample_bytree = c(0.75),
subsample = c(0.50),
min_child_weight = c(0))
)
mod_list <- list(lm = lm,pca = lm_pca,glmnet = glmnet,rf = rf, XGBTree = xgbTree, gbm = gbm, rpart = rpart, svmLinear = svmLinear)
resamp <- resamples(mod_list)
bwplot(resamp,metric = "RMSE")
xgbTree
xgbTree <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "xgbTree",
trControl = myControl,
tuneGrid = expand.grid(
nrounds = 1000,
eta = c(0.01, 0.001, 0.0001),
max_depth = c(2, 4, 6, 8, 10),
gamma = 1
)
)
xgbTree <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "xgbTree",
trControl = myControl,
tuneGrid = expand.grid(
nrounds= seq(100,1000,100),
max_depth = seq(0,10,2),
eta = c(0.001,.01,0.1),
gamma = seq(0,1,.1),
colsample_bytree = seq(0,1,.25),
subsample = seq(0,1,.25),
min_child_weight = seq(0,1,.25)
)
)
expand.grid(
nrounds= seq(100,1000,100),
max_depth = seq(0,10,2),
eta = c(0.001,.01,0.1),
gamma = seq(0,1,.5),
colsample_bytree = seq(0,1,.25),
subsample = seq(0,1,.25),
min_child_weight = seq(0,1,.5)
)
expand.grid(
nrounds= seq(100,350,500),
max_depth = seq(0,10,2),
eta = c(0.001,.01,0.1),
gamma = seq(0,1,.5),
colsample_bytree = seq(0,1,.25),
subsample = seq(0,1,.25),
min_child_weight = seq(0,1,.5)
)
expand.grid(
nrounds= seq(100,350,500),
max_depth = c(2,4,6,8),
eta = c(.01,0.1),
gamma = seq(0,1,.5),
colsample_bytree = seq(0,1,.25),
subsample = seq(0,1,.25),
min_child_weight = seq(0,1,.5)
)
expand.grid(
nrounds= 1000,
max_depth = c(2,4,6,8),
eta = c(.01,0.1),
gamma = seq(0,1,.5),
colsample_bytree = seq(0,1,.25),
subsample = seq(0,1,.25),
min_ch
expand.grid(
nrounds= 1000,
max_depth = c(2,4,6,8),
eta = c(.01,0.1),
gamma = seq(0,1,.5),
colsample_bytree = seq(0,1,.25),
subsample = seq(0,1,.25),
min_child_weight = seq(0,1,.5)
)
xgbTree <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "xgbTree",
trControl = myControl,
tuneGrid = expand.grid(
nrounds= 1000,
max_depth = c(2,4,6,8),
eta = c(.01,0.1),
gamma = seq(0,1,.5),
colsample_bytree = seq(0,1,.25),
subsample = seq(0,1,.25),
min_child_weight = seq(0,1,.5)
)
)
expand.grid(
nrounds= 1000,
max_depth = c(3,6),
eta = c(.01,0.1),
gamma = seq(0,1,.5),
colsample_bytree = c(.5,.7),
subsample = seq(0,1,.5),
min_child_weight = seq(0,1,.5)
)
xgbTree <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "xgbTree",
trControl = myControl,
tuneGrid = expand.grid(
nrounds= 1000,
max_depth = c(3,6),
eta = c(.01,0.1),
gamma = seq(0,1,.5),
colsample_bytree = c(.5,.7),
subsample = seq(0,1,.5),
min_child_weight = seq(0,1,.5)
)
)
##XGBoost mo
xgbTree <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "xgbTree",
trControl = myControl,
tuneGrid = expand.grid(
nrounds= 500,
max_depth = c(3,6),
eta = c(0.1,0.2,0.3),
gamma = 0,
colsample_bytree = c(.5,.7),
subsample = c(0.5,0.8),
min_child_weight = 0
)
)
xgbTree
min(xgbTree$results$RMSE)
rm(list = ls())
train <- read.csv(here("data","train.csv"), stringsAsFactors = F)
train <- train %>% select(-Id)
#Look at missing values for each column
map_df(train, ~sum(is.na(.))) %>% gather() %>%
filter(value > 0) %>%
ggplot(.,aes(x = reorder(key,-value), y = value)) +
geom_bar(stat="identity") +
labs(title = "Missing Values",x="") +
theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
#Replace missing values with "none" or "0" based on categorical vs numeric and combine back to create an imputed train dataframe
train_num <- train %>% select_if(is.numeric)
train_cat <- train %>% select_if(is.character)
train_num[is.na(train_num)] <- 0
train_cat[is.na(train_cat)] <- "None"
train_cat <- map_df(train_cat,as.factor)
train_pp <- cbind(train_cat,train_num)
rm(train_cat,train_num)
#define training folds and steps for modeling
set.seed(1108)
myFolds <- createFolds(train_pp$SalePrice,10)
myControl <- trainControl(
verboseIter = T,
savePredictions = T,
index = myFolds
)
## Multiple Regression Models
lm <- train(
SalePrice~.,
data = train_pp,
preProcess = c("nzv","center","scale"),
metric = "RMSE",
method = "lm",
trControl = myControl
)
lm_pca <- train(
SalePrice~.,
data = train_pp,
preProcess = c("zv","center","scale","pca"),
metric = "RMSE",
method = "lm",
trControl = myControl
)
train <- read.csv(here("data","train.csv"), stringsAsFactors = F)
here()
library(here)
library(tidyverse)
library(caret)
train <- read.csv(here("data","train.csv"), stringsAsFactors = F)
here()
library(here)
here()
library(here)
library(tidyverse)
library(caret)
load("/home/sobo/R/kaggle/housing_prices_revisited/caretmod.RData")
load("/home/sobo/R/kaggle/caret_tutorial/caretmod.RData")
str(train_pp)
rf1 <- train(
SalePrice~.,
data = train_pp,
metric = "RMSE",
method = "rf",
trControl = myControl,
tuneGrid = expand.grid(
mtry = seq(70, 150, 5)
)
)
head(train_pp)
rf2 <- train(
x=train_pp[,1:79],
y=train_pp[,80],
metric = "RMSE",
method = "rf",
trControl = myControl,
tuneGrid = expand.grid(
mtry = seq(70, 150, 5)
)
)
min(rf2$results$RMSE)
min(rf1$results$RMSE)
library(AmesHousing)
here()
test <- read.csv(here("data","test.csv"), stringsAsFactors = F)
test <- test %>% select(-Id)
#Replace missing values with "none" or "0" based on categorical vs numeric
test_num <- test %>% select_if(is.numeric)
test_cat <- test %>% select_if(is.character)
test_num[is.na(test_num)] <- 0
test_cat[is.na(test_cat)] <- "None"
test_cat <- map_df(test_cat,as.factor)
#Combine replaced dataframes
test_pp <- cbind(test_cat,test_num)
?predict
predictions <- predict(rf1,test_pp)
